{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F4YxwviWtesV"
   },
   "source": [
    "# RNN pour l'analyse de sentiments\n",
    "\n",
    "Nous allons maintenant faire une analyse de sentiments sur le même jeu de données en utilisant les réseaux de neurones récurrents\n",
    "\n",
    "## Réseaux de neurones récurrents\n",
    "\n",
    "Les réseaux de neurones récurrents ou (RNN), sont souvent utilisés pour analyser des séquences.\n",
    "\n",
    "En effet, dans les réseaux de neurones généraux, un input est traité par un certain nombre de couches et un output est produit à la sortie, avec l'hypothèse que deux inputs successifs sont indépendants.\n",
    "\n",
    "Cependant, cette hypothèse n'est pas correcte dans un certain nombre de scénarios. \n",
    "Par exemple, si on veut prédire le mot suivant dans une séquence, il est indispensable de considérer la dépendance des observations précédentes.\n",
    "    \n",
    "Dans notre cas, le modèle RNN prend une séquence de mots $X=\\{x_1, ..., x_T\\}$, une à la fois, et produit un état caché $h$, pour chaque mot.\n",
    "On utilise le RNN en lui donnant le mot courant $x_t$ ainsi que l'état caché du mot précédent, $h_{t-1}$, pour produire l'état caché suivant, $h_t$.\n",
    "\n",
    "\n",
    "$$h_t = \\text{RNN}(x_t, h_{t-1})$$\n",
    "\n",
    "\n",
    "Une fois que l'on a notre état caché final, $h_T$, obtenu après avoir donné le dernier mot de la séquence $x_T$ au modèle, on le donne à une couche linéaire $f$, (qui s'appelle également fully connected layer), pour recevoir notre sentiment prédit, $\\hat{y} = f(h_T)$.\n",
    "\n",
    "<center> <img src=\"RNN.png\" alt=\"drawing\" width=\"700\"/>\n",
    "        \n",
    "        \n",
    "Cette illustration montre un exemple de phrase, avec le RNN prédisant 0, c'est-à-dire que le sentiment est négatif. Le RNN est représenté en orange et la couche linéaire est en gris. On utilise le même RNN pour chaque mot, c'est-à-dire qu'il a les mêmes paramètres. L'état initial caché $h_0$, est un tensor initialisé à zéro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IINy-8uQtesY"
   },
   "source": [
    "## Préparation des données\n",
    "\n",
    "Dans ce notebook, on utilise la librairie torch et TorchText.\n",
    "\n",
    "TorchText a une méthode `Field` qui sert à définir comment les données brutes doivent être traitées.\n",
    "\n",
    "La méthode `TEXT` définit comment les commentaires doivent être traités, et `LABEL` comment les labels doivent être traités. \n",
    "\n",
    "`TEXT` a un argument `tokenize`, qui par défaut split les chaînes de caractères en espaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SV06LPyQtesa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(sequential=True,lower=True,include_lengths = True)\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sépare les données en train et test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille des données train: 18163\n",
      "Taille des données de validation: 2270\n",
      "Taille des données test: 2271\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "        path='./data/', train='train.csv',\n",
    "        validation='valid.csv', test='test.csv', format='csv', skip_header=True,\n",
    "        fields=[('text', TEXT), ('label', LABEL)])\n",
    "\n",
    "print(f'Taille des données train: {len(train_data)}')\n",
    "print(f'Taille des données de validation: {len(valid_data)}')\n",
    "print(f'Taille des données test: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NOCX0qGNtesw"
   },
   "source": [
    "On affiche un exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "XXxXnQwctesx",
    "outputId": "bca3747b-655d-4ae7-fb2f-29b49a373eb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['this', 'movie', 'is', 'a', 'gem', 'because', 'it', 'moves', 'with', 'soft,', 'but', 'firm', 'resolution.<br', '/><br', '/>i', 'caution', 'viewers', 'that', 'although', 'it', 'is', 'billed', 'as', 'a', 'corporate', 'spy', 'thriller', 'and', 'ms', 'liu', 'is', 'there,', 'it', 'moves', 'at', 'a', 'deftly', 'purposeful', 'yet', 'sedate', 'pace.', \"it's\", 'not', 'about', 'explosions,', 'car', 'chases,', 'or', 'flying', 'bullets.', 'you', 'must', 'be', 'patient', 'and', 'instead,', 'note', 'the', 'details', 'here.', \"it's\", 'sedate', 'because', \"that's\", 'what', 'the', 'main', 'character', 'is.', 'the', 'viewer', 'has', 'to', 'watch', 'him', 'and', 'think', 'as', 'this', 'story', 'unfolds.<br', '/><br', '/>i', 'will', 'not', 'give', 'spoilers--', 'because', 'that', 'destroys', 'the', 'point', 'of', 'watching.', 'the', 'plot', 'is', 'what', \"you've\", 'read', 'from', 'the', 'other', 'postings:', 'an', 'average', 'white-collar', 'guy,', 'seeking', 'change', 'and', 'adventure,', 'signs', 'on', 'for', 'a', 'corporate', 'spy', 'job.', 'just', 'go', 'somewhere', 'and', 'secretly', 'record', 'and', 'transmit', 'inside', 'data.', '<br', '/><br', '/>take', 'it', 'from', 'there.<br', '/><br', '/>this', 'movie', 'starts', 'at', 'a', 'surreal', 'walk--', 'with', 'a', 'background', 'tang', 'of', 'corporate', 'disillusionment', 'that', 'entwines', 'itself', 'with', 'quintessential,', 'underlying', 'suburban', 'paranoia.<br', '/><br', '/>then', 'it', 'begins', 'to', 'accelerate.<br', '/><br', '/>the', 'acting', 'on', 'all', 'parts', 'is', 'superb--', 'and', 'yes,', 'some', 'of', 'the', 'acts', 'are', 'caricature', 'characters.', 'but', 'they', 'all', 'fit,', 'and', 'they', 'entertain.', 'and', 'the', 'light', 'piano', 'rhyme', 'in', 'the', 'background', 'is', 'just', 'perfect', 'as', 'the', 'soft,', 'soft', 'key', 'sinister', 'theme:', 'all', 'is', 'not', 'right', 'at', 'the', 'beginning.<br', '/><br', '/>and', 'at', 'the', 'end:', 'all', 'is', 'not', 'what', 'it', 'seems.<br', '/><br', '/>get', 'comfortable', 'and', 'turn', 'the', 'lights', 'down', 'to', 'watch', 'this', 'one--', 'and', 'turn', 'up', 'the', 'sound:', 'this', 'movie', 'wants', 'you', 'to', 'listen.'], 'label': '0'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V_a2QAqztes7"
   },
   "source": [
    "On crée un échantillon de données de validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2JwQ2BY0tetK"
   },
   "source": [
    "On crée un vocabulaire sur l'échantillon train avec la méthode `build_vocab`et on ne prend que 25000 mots pour diminuer la dimension de la matrice d'embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j8gQvkW7tetL"
   },
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25_000\n",
    "\n",
    "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "print(f\"Nombre de tokens unique dans le TEXT: {len(TEXT.vocab)}\") \n",
    "print(f\"Nombre unique de LABEL: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H-EuaMfGtetU"
   },
   "source": [
    "Les deux valeurs supplémentaires dans le vocabulaire du TEXT sont les tokens `<unk>` et `<pad>`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "m0yMEfHptetW",
    "outputId": "b4503fa3-92e7-479b-c64b-79797e8ad0db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 269481), ('a', 134161), ('and', 132447), ('of', 121047), ('to', 111764), ('is', 88203), ('in', 76185), (',', 55882), ('that', 55193), ('this', 53162), ('it', 52750), ('i', 51962), ('.', 46745), ('as', 38794), ('with', 36382), ('for', 35734), ('was', 34423), ('/><br', 33836), ('but', 32810), ('his', 26298)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nXX3_jXLtetn"
   },
   "source": [
    "We can also check the labels, ensuring 0 is for negative and 1 is for positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "P4i4-Fhjteto",
    "outputId": "9e71e222-9875-436f-e807-2d231626177a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'0': 0, '1': 1})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j8ovGiuJtett"
   },
   "source": [
    "La dernière étape de la préparation des données consiste à créer les itérateurs. Nous les parcourons dans la boucle d'apprentissage / d'évaluation, et ils retournent un lot d'exemples (indexés et convertis en tenseurs) à chaque itération.\n",
    "\n",
    "On utilise `BucketIterator` qui est un itérateur qui renverra un lot d'exemples où chaque exemple est d'une longueur similaire, minimisant la quantité de padding par exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vx_Fb_59tetu"
   },
   "outputs": [],
   "source": [
    "# utilisation du GPU si possible \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 2678x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 1263x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 927x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 1090x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 1187x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 1046x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 2181x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 1310x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 2044x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 675x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 940x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 826x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 790x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 1040x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 999x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 1562x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 950x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 1329x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 891x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 1889x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 1180x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 1832x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 746x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 1439x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 1076x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 882x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 733x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 1435x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 1080x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 961x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 1147x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 819x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 993x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 1526x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 914x64 (GPU 0)]', '[torch.cuda.LongTensor of size 64 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 31]\n",
      "\t[.text]:('[torch.cuda.LongTensor of size 1129x31 (GPU 0)]', '[torch.cuda.LongTensor of size 31 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 31 (GPU 0)]\n"
     ]
    }
   ],
   "source": [
    "for tab in test_iterator:\n",
    "    print(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tz0537L1tetx"
   },
   "source": [
    "## Construction du modèle\n",
    "\n",
    "Le modèle RNN utilisé se compose des couches suivantes : \n",
    "\n",
    "- _embedding_ : utilisé pour transformer notre vecteur one hot encoder (dont la plupart des éléments sont des 0) en un vecteur embedding dense (dense car la dimensionnalité est beaucoup plus petite et tous les éléments sont des nombres réels). De plus, les mots qui ont un impact similaire sur le sentiment de la revue sont mappés de manière rapprochée dans cet espace vectoriel dense.\n",
    "- _RNN_ : prend le vecteur dense et le précédent état caché $h_{t-1}$, et calcule l'état caché suivant $h_t$.\n",
    "- _linéaire_ : prend le dernier état caché, le met dans un couche fully connected $f(h_T)$ qui le transfome en output prédit.\n",
    "\n",
    "On appelle la méthode `forward` lorsque l'on donne nos exemple à notre modèle.\n",
    "\n",
    "Chaque batch, `text` est un tensor de dimension _**[sentence length, batch size]**_. C'est un batch de commentaires, \n",
    "\n",
    "Each batch, , is a tensor of size . That is a batch of sentences, each having each word converted into a one-hot vector. \n",
    "\n",
    "You may notice that this tensor should have another dimension due to the one-hot vectors, however PyTorch conveniently stores a one-hot vector as it's index value, i.e. the tensor representing a sentence is just a tensor of the indexes for each token in that sentence. The act of converting a list of tokens into a list of indexes is commonly called *numericalizing*.\n",
    "\n",
    "The input batch is then passed through the embedding layer to get `embedded`, which gives us a dense vector representation of our sentences. `embedded` is a tensor of size _**[sentence length, batch size, embedding dim]**_.\n",
    "\n",
    "`embedded` is then fed into the RNN. In some frameworks you must feed the initial hidden state, $h_0$, into the RNN, however in PyTorch, if no initial hidden state is passed as an argument it defaults to a tensor of all zeros.\n",
    "\n",
    "The RNN returns 2 tensors, `output` of size _**[sentence length, batch size, hidden dim]**_ and `hidden` of size _**[1, batch size, hidden dim]**_. `output` is the concatenation of the hidden state from every time step, whereas `hidden` is simply the final hidden state. We verify this using the `assert` statement. Note the `squeeze` method, which is used to remove a dimension of size 1. \n",
    "\n",
    "Finally, we feed the last hidden state, `hidden`, through the linear layer, `fc`, to produce a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O8BPYwRGtety"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        \n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "\n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        output, hidden = self.rnn(embedded)\n",
    "        \n",
    "        #output = [sent len, batch size, hid dim]\n",
    "        #hidden = [1, batch size, hid dim]\n",
    "        \n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        \n",
    "        return self.fc(hidden.squeeze(0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1KBgfaFitet5"
   },
   "source": [
    "We now create an instance of our RNN class. \n",
    "\n",
    "The input dimension is the dimension of the one-hot vectors, which is equal to the vocabulary size. \n",
    "\n",
    "The embedding dimension is the size of the dense word vectors. This is usually around 50-250 dimensions, but depends on the size of the vocabulary.\n",
    "\n",
    "The hidden dimension is the size of the hidden states. This is usually around 100-500 dimensions, but also depends on factors such as on the vocabulary size, the size of the dense vectors and the complexity of the task.\n",
    "\n",
    "The output dimension is usually the number of classes, however in the case of only 2 classes the output value is between 0 and 1 and thus can be 1-dimensional, i.e. a single scalar real number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3A_TUXSftet8"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R4tkl11AteuA"
   },
   "source": [
    "Let's also create a function that will tell us how many trainable parameters our model has so we can compare the number of parameters across different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DHhyWBk3teuA",
    "outputId": "9586cff6-25a5-49cf-c85f-771a20ee6a29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,592,105 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zGjJ1BSSteuF"
   },
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4fcMx95rteuH"
   },
   "source": [
    "Now we'll set up the training and then train the model.\n",
    "\n",
    "First, we'll create an optimizer. This is the algorithm we use to update the parameters of the module. Here, we'll use _stochastic gradient descent_ (SGD). The first argument is the parameters will be updated by the optimizer, the second is the learning rate, i.e. how much we'll change the parameters by when we do a parameter update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MC34zFI4teuI"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ldK_vHILteuN"
   },
   "source": [
    "Next, we'll define our loss function. In PyTorch this is commonly called a criterion. \n",
    "\n",
    "The loss function here is _binary cross entropy with logits_. \n",
    "\n",
    "Our model currently outputs an unbound real number. As our labels are either 0 or 1, we want to restrict the predictions to a number between 0 and 1. We do this using the _sigmoid_ or _logit_ functions. \n",
    "\n",
    "We then use this this bound scalar to calculate the loss using binary cross entropy. \n",
    "\n",
    "The `BCEWithLogitsLoss` criterion carries out both the sigmoid and the binary cross entropy steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bEn4T95ZteuN"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NpprToLYteuQ"
   },
   "source": [
    "Using `.to`, we can place the model and the criterion on the GPU (if we have one). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kh294K1JteuR"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w42XP6EbteuV"
   },
   "source": [
    "Our criterion function calculates the loss, however we have to write our function to calculate the accuracy. \n",
    "\n",
    "This function first feeds the predictions through a sigmoid layer, squashing the values between 0 and 1, we then round them to the nearest integer. This rounds any value greater than 0.5 to 1 (a positive sentiment) and the rest to 0 (a negative sentiment).\n",
    "\n",
    "We then calculate how many rounded predictions equal the actual labels and average it across the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4G8cW2IpteuX"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cn8UE87Gteuc"
   },
   "source": [
    "The `train` function iterates over all examples, one batch at a time. \n",
    "\n",
    "`model.train()` is used to put the model in \"training mode\", which turns on _dropout_ and _batch normalization_. Although we aren't using them in this model, it's good practice to include it.\n",
    "\n",
    "For each batch, we first zero the gradients. Each parameter in a model has a `grad` attribute which stores the gradient calculated by the `criterion`. PyTorch does not automatically remove (or \"zero\") the gradients calculated from the last gradient calculation, so they must be manually zeroed.\n",
    "\n",
    "We then feed the batch of sentences, `batch.text`, into the model. Note, you do not need to do `model.forward(batch.text)`, simply calling the model works. The `squeeze` is needed as the predictions are initially size _**[batch size, 1]**_, and we need to remove the dimension of size 1 as PyTorch expects the predictions input to our criterion function to be of size _**[batch size]**_.\n",
    "\n",
    "The loss and accuracy are then calculated using our predictions and the labels, `batch.label`, with the loss being averaged over all examples in the batch.\n",
    "\n",
    "We calculate the gradient of each parameter with `loss.backward()`, and then update the parameters using the gradients and optimizer algorithm with `optimizer.step()`.\n",
    "\n",
    "The loss and accuracy is accumulated across the epoch, the `.item()` method is used to extract a scalar from a tensor which only contains a single value.\n",
    "\n",
    "Finally, we return the loss and accuracy, averaged across the epoch. The `len` of an iterator is the number of batches in the iterator.\n",
    "\n",
    "You may recall when initializing the `LABEL` field, we set `dtype=torch.float`. This is because TorchText sets tensors to be `LongTensor`s by default, however our criterion expects both inputs to be `FloatTensor`s. Setting the `dtype` to be `torch.float`, did this for us. The alternative method of doing this would be to do the conversion inside the `train` function by passing `batch.label.float()` instad of `batch.label` to the criterion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JUK2BZs6teud"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "               \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        print('predictions',predictions.size())\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        print('loss',loss.size())\n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ufZOWJenteug"
   },
   "source": [
    "`evaluate` is similar to `train`, with a few modifications as you don't want to update the parameters when evaluating.\n",
    "\n",
    "`model.eval()` puts the model in \"evaluation mode\", this turns off _dropout_ and _batch normalization_. Again, we are not using them in this model, but it is good practice to include them.\n",
    "\n",
    "No gradients are calculated on PyTorch operations inside the `with no_grad()` block. This causes less memory to be used and speeds up computation.\n",
    "\n",
    "The rest of the function is the same as `train`, with the removal of `optimizer.zero_grad()`, `loss.backward()` and `optimizer.step()`, as we do not update the model's parameters when evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K6B9sga2teuh"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model.forward(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ny0GA1QNteul"
   },
   "source": [
    "We'll also create a function to tell us how long an epoch takes to compare training times between models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9-yEE80qteum"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FUF-j3L5teup"
   },
   "source": [
    "We then train the model through multiple epochs, an epoch being a complete pass through all examples in the training and validation sets.\n",
    "\n",
    "At each epoch, if the validation loss is the best we have seen so far, we'll save the parameters of the model and then after training has finished we'll use that model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "id": "k1oHzxVZteuq",
    "outputId": "b2da54ea-d1b2-40ce-dc9b-77be191b5239"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "embedding(): argument 'indices' (position 2) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ec02fb851491>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-04dc736151e4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predictions'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-664b59d78c13>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#text = [sent len, batch size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#embedded = [sent len, batch size, emb dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 3\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ysk_ln28teut"
   },
   "source": [
    "You may have noticed the loss is not really decreasing and the accuracy is poor. This is due to several issues with the model which we'll improve in the next notebook.\n",
    "\n",
    "Finally, the metric we actually care about, the test loss and accuracy, which we get from our parameters that gave us the best validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aTbFhWLrteut"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('tut1-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    print(tokenized)\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    print(indexed)\n",
    "    length = [len(indexed)]\n",
    "    print(length)\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    print(tensor)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    print(tensor)\n",
    "    length_tensor = torch.LongTensor(length)\n",
    "    print(length_tensor)\n",
    "    prediction = torch.sigmoid(model(tensor, length_tensor))\n",
    "    print(prediction)\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sentiment(model, \"This film is terrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sentiment(model, \"This film is great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copie de 1 - Simple Sentiment Analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
