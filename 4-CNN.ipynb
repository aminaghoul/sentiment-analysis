{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "\n",
    "Les couches convolutives utilisent des filtres qui balaient une image et produisent une version traitée de l'image. Cette version traitée de l'image peut être introduite dans une autre couche convolutionnelle ou une couche linéaire. Chaque filtre a une forme, par ex. un filtre 3x3 couvre une zone de 3 pixels de large et 3 pixels de haut de l'image, et chaque élément du filtre a un poids qui lui est associé, le filtre 3x3 aurait 9 poids. Dans le traitement d'image traditionnel, ces poids ont été spécifiés à la main par des ingénieurs, mais le principal avantage des couches convolutives dans les réseaux de neurones est que ces poids sont appris par rétropropagation.\n",
    "\n",
    "L'idée intuitive derrière l'apprentissage des poids est que les couches convolutives agissent comme des extracteurs de features, extrayant les parties de l'image les plus importantes pour l'objectif du CNN. Par exemple, si vous utilisez un CNN pour détecter des visages dans une image, le CNN peut rechercher des caractéristiques telles que l'existence d'un nez, d'une bouche ou d'une paire d'yeux dans l'image.\n",
    "\n",
    "De la même manière qu'un filtre 3x3 peut regarder sur une image, un filtre 1x2 peut regarder sur 2 mots séquentiels dans un morceau de texte, c'est-à-dire un bi-gramme. Dans ce modèle CNN, nous utiliserons plusieurs filtres de tailles différentes qui examineront les bi-grammes (un 1x2 filter), tri-grammes (un filtre 1x3) et / ou n-grammes (un 1x $ n $ filtre) dans le texte.\n",
    "\n",
    "L'intuition ici est que l'apparition de certains bi-grammes, tri-grammes et n-grammes dans la revue sera une bonne indication du sentiment final.\n",
    "\n",
    "## Préparer les données\n",
    "\n",
    "Comme les couches convolutionnelles s'attendent à ce que la dimension du batch soit la première, nous pouvons dire à TorchText de renvoyer les données déjà permutées en utilisant l'argument batch_first = True dans la méthode `Field`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(batch_first = True)\n",
    "LABEL = data.LabelField(dtype = torch.float)\n",
    "\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "        path='./data/', train='train.csv',\n",
    "        validation='valid.csv', test='test.csv', format='csv', skip_header=True,\n",
    "        fields=[('text', TEXT), ('label', LABEL)])\n",
    "\n",
    "MAX_VOCAB_SIZE = 25_000\n",
    "\n",
    "TEXT.build_vocab(train_data, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Itérateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device, sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construire le modèle\n",
    "\n",
    "Le texte est en 1 dimension. Cependant, nous savons que la première étape de presque tous nos notebooks précédents consiste à convertir les mots en embedding. C'est ainsi que nous pouvons visualiser nos mots en 2 dimensions, chaque mot le long d'un axe et les éléments de vecteurs sur l'autre dimension.\n",
    "On peut alors utiliser un filtre qui est **[n x emb_dim]**. Cela couvrira entièrement les mots séquentiels $ n $, car leur largeur sera de dimension emb_dim.\n",
    "\n",
    "La prochaine étape de notre modèle consiste à utiliser le pooling (en particulier le pooling max) sur la sortie des couches convolutives afin de prendre la valeur maximale sur une dimension.\n",
    "\n",
    " - Nous implémentons les couches convolutives avec nn.Conv2d. L'argument in_channels est le nombre de \"channels\" nous n'avons qu'un seul \"channel\", le texte lui-même. Le out_channels est le nombre de filtres et le kernel_size est la taille des filtres. Chacun de nos kernel_sizes va être [n x emb_dim] où $ n $ est la taille des n-grammes.\n",
    " - En PyTorch, les RNN veulent l'entrée avec la dimension batch en second, tandis que les CNN veulent d'abord la dimension batch - nous n'avons pas besoin de permuter les données ici car nous avons déjà défini batch_first = True dans notre champ TEXT.\n",
    " - Nous passons ensuite les tenseurs à travers les couches convolutives et de pooling, en utilisant la fonction d'activation ReLU après les couches convolutives. La taille de la sortie de la couche convolutive dépend de la taille de l'entrée, et différents lots contiennent des phrases de différentes longueurs.\n",
    " - Enfin, nous effectuons des dropouts sur les sorties de filtre concaténées, puis nous les faisons passer à travers une couche linéaire pour faire nos prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le modèle a 2,620,801 paramètres à entraîner\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "                \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)  \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)  \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):           \n",
    "        \n",
    "        embedded = self.embedding(text)  \n",
    "        embedded = embedded.unsqueeze(1) \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]        \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved] \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "            \n",
    "        return self.fc(cat)\n",
    "    \n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 1\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'Le modèle a {count_parameters(model):,} paramètres à entraîner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Retourne l'accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "\n",
    "def recall(preds, y):\n",
    "    '''\n",
    "    Retourne le recall\n",
    "    '''\n",
    "    y_pred = torch.round(torch.sigmoid(preds))\n",
    "    y_true = (y_pred == y).float()       \n",
    "    \n",
    "    tp = (y_true * y_pred).sum().float()\n",
    "    tn = ((1 - y_true) * (1 - y_pred)).sum().float()\n",
    "    fp = ((1 - y_true) * y_pred).sum().float()\n",
    "    fn = (y_true * (1 - y_pred)).sum().float()\n",
    "    \n",
    "    if (tp + fn) == 0:\n",
    "        recall = torch.zeros(1)\n",
    "        \n",
    "    recall = tp / (tp + fn)\n",
    "    return recall\n",
    "\n",
    "\n",
    "\n",
    "def f1_loss(preds, y):\n",
    "    '''\n",
    "    Retourne le score F1\n",
    "    '''  \n",
    "    y_pred = torch.round(torch.sigmoid(preds))\n",
    "    y_true = (y_pred == y).float() \n",
    "            \n",
    "    tp = (y_true * y_pred).sum().float()\n",
    "    tn = ((1 - y_true) * (1 - y_pred)).sum().float()\n",
    "    fp = ((1 - y_true) * y_pred).sum().float()\n",
    "    fn = (y_true * (1 - y_pred)).sum().float()\n",
    "    \n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    \n",
    "    if (tp + fn) == 0 or (tp + fp) == 0 or (recall + precision == 0):\n",
    "        f1 = torch.zeros(1)\n",
    "    else:\n",
    "        f1 = 2* (precision*recall) / (precision + recall)\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 24s\n",
      "\tTrain Loss: 0.666 | Train Acc: 59.94%| Train Recall: 35.68%| Train F1: 42.66%\n",
      "\t Val. Loss: 0.583 |  Val. Acc: 71.54%| Val. Recall: 33.39%| Val. F1: 46.06%\n",
      "Epoch: 02 | Epoch Time: 0m 23s\n",
      "\tTrain Loss: 0.489 | Train Acc: 76.36%| Train Recall: 41.62%| Train F1: 53.28%\n",
      "\t Val. Loss: 0.429 |  Val. Acc: 80.94%| Val. Recall: 48.35%| Val. F1: 58.55%\n",
      "Epoch: 03 | Epoch Time: 0m 23s\n",
      "\tTrain Loss: 0.353 | Train Acc: 84.67%| Train Recall: 43.80%| Train F1: 57.23%\n",
      "\t Val. Loss: 0.374 |  Val. Acc: 84.61%| Val. Recall: 42.00%| Val. F1: 56.18%\n",
      "Epoch: 04 | Epoch Time: 0m 23s\n",
      "\tTrain Loss: 0.262 | Train Acc: 89.27%| Train Recall: 44.48%| Train F1: 58.95%\n",
      "\t Val. Loss: 0.372 |  Val. Acc: 85.08%| Val. Recall: 44.52%| Val. F1: 57.72%\n",
      "Epoch: 05 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.187 | Train Acc: 92.85%| Train Recall: 44.78%| Train F1: 60.05%\n",
      "\t Val. Loss: 0.389 |  Val. Acc: 84.48%| Val. Recall: 42.25%| Val. F1: 56.28%\n",
      "Epoch: 06 | Epoch Time: 0m 23s\n",
      "\tTrain Loss: 0.131 | Train Acc: 95.23%| Train Recall: 45.08%| Train F1: 60.86%\n",
      "\t Val. Loss: 0.436 |  Val. Acc: 84.05%| Val. Recall: 40.74%| Val. F1: 55.25%\n",
      "Epoch: 07 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.089 | Train Acc: 96.93%| Train Recall: 45.18%| Train F1: 61.31%\n",
      "\t Val. Loss: 0.457 |  Val. Acc: 84.56%| Val. Recall: 43.20%| Val. F1: 56.87%\n",
      "Epoch: 08 | Epoch Time: 0m 23s\n",
      "\tTrain Loss: 0.064 | Train Acc: 97.91%| Train Recall: 45.30%| Train F1: 61.60%\n",
      "\t Val. Loss: 0.505 |  Val. Acc: 83.70%| Val. Recall: 42.69%| Val. F1: 56.32%\n",
      "Epoch: 09 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.046 | Train Acc: 98.54%| Train Recall: 45.29%| Train F1: 61.77%\n",
      "\t Val. Loss: 0.565 |  Val. Acc: 83.56%| Val. Recall: 41.57%| Val. F1: 55.57%\n",
      "Epoch: 10 | Epoch Time: 0m 23s\n",
      "\tTrain Loss: 0.035 | Train Acc: 98.95%| Train Recall: 45.33%| Train F1: 61.87%\n",
      "\t Val. Loss: 0.611 |  Val. Acc: 83.47%| Val. Recall: 42.17%| Val. F1: 55.90%\n"
     ]
    }
   ],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_rec = 0\n",
    "    epoch_f1 = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()  \n",
    "        predictions = model(batch.text).squeeze(1)  \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        rec = recall(predictions, batch.label)\n",
    "        f1 = f1_loss(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()    \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        epoch_rec += rec.item()\n",
    "        epoch_f1 += f1.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_rec / len(iterator), epoch_f1 / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_rec = 0\n",
    "    epoch_f1 = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "            rec = recall(predictions, batch.label)\n",
    "            f1 = f1_loss(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_rec += rec.item()\n",
    "            epoch_f1 += f1.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_rec / len(iterator), epoch_f1 / len(iterator)\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "N_EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc, train_rec, train_f1 = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc, valid_rec, valid_f1 = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut4-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%| Train Recall: {train_rec*100:.2f}%| Train F1: {train_f1*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%| Val. Recall: {valid_rec*100:.2f}%| Val. F1: {valid_f1*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.352 | Test Acc: 84.97%| Test Recall: 46.92%| Test F1: 60.15%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut4-model.pt'))\n",
    "\n",
    "test_loss, test_acc, test_rec, test_f1 = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%| Test Recall: {test_rec*100:.2f}%| Test F1: {test_f1*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def predict_sentiment(model, sentence, min_len = 5):\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    if len(tokenized) < min_len:\n",
    "        tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    prediction = torch.sigmoid(model(tensor))\n",
    "    \n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9583509564399719"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"This film is terrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07189281284809113"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"This film is great\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Références :\n",
    "\n",
    " - https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/4%20-%20Convolutional%20Sentiment%20Analysis.ipynb\n",
    " - https://arxiv.org/pdf/1408.5882.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
